{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import oandapy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set initial year for data y1, end year of data y2, granularity of data gran.\n",
    "y1 = '2005'\n",
    "y2 = '2018'\n",
    "gran = 'M10'\n",
    "\n",
    "# Open oanda client with access token in practice environmet\n",
    "oanda  = oandapy.API(environment=\"practice\",\n",
    "                     access_token=\"\")\n",
    "\n",
    "\n",
    "# Set Default Values for M10\n",
    "# \n",
    "# Granularity of data in pandas freq, and as integer in minutes dl_interval,\n",
    "# Granularity for output format granop, interval size as tine step diff,\n",
    "# offset between two different download attempts offset (5000 is maximum via oanda)\n",
    "freq = '10T'\n",
    "dl_interval = 10\n",
    "granop = gran\n",
    "diff = '0 days, 00:10:00'\n",
    "offset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\n",
    "## Potential customization for other intervals to write as function\n",
    "# dl_interval = gran[1:]\n",
    "\n",
    "# if gran[0] == 'M':\n",
    "# \tfreq = dl_interval + 'T'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'M0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:0' + dl_interval + ':00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'M' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:' + dl_interval + ':00'\n",
    "# \toffset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\t\n",
    "# elif gran[0] == 'H':\n",
    "# \tfreq = str(dl_interval) + 'H'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'H0' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 0' + dl_interval + ':00:00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'H' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, ' + dl_interval + ':00:00'\n",
    "# \toffset = pd.DateOffset(hours=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'S':\n",
    "# \tfreq = str(dl_interval) + 'S'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'S0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:00:0' + dl_interval\n",
    "# \telse:\n",
    "# \t\tgranop = 'S' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 00:00:' + dl_interval\n",
    "# \toffset = pd.DateOffset(seconds=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'D':\n",
    "# \tfreq = 'D'\n",
    "# \tgranop = gran\n",
    "# \tdiff = '1 day, 00:00:00'\n",
    "# \toffset = pd.DateOffset(days=4800*int(dl_interval))\n",
    "\n",
    "\n",
    "# Function to download from oanda\n",
    "def oanda_download(df, x0, xf, gran, instrument):\n",
    "    # Each call of the function downloads data between x0 and xf that hasn't been downloaded previously.\n",
    "    # To make as few requests to oanda as possible, make the interval as large as safely possible.\n",
    "    # Oanda allows 5000 data points at a time; for margin we pull data from up to 4800 time points.\n",
    "    # This is to account for potential duplicate data that'd throw an exception.\n",
    "\tif gran[0] == 'S':\n",
    "\t\toffset = pd.DateOffset(seconds=4800*int(gran[1:]))\n",
    "\telif gran[0] == 'M':\n",
    "\t\toffset = pd.DateOffset(minutes=4800*int(gran[1:]))\n",
    "\telif gran[0] == 'H':\n",
    "\t\toffset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "\telse:\n",
    "\t\toffset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "\t\n",
    "    # If the end point given by user is later than current time, shorten interval.\n",
    "\tif dt.datetime.now() < xf:\n",
    "\t\txf = dt.datetime.now()\n",
    "\t\n",
    "    # Download data between x0 and x1, which corresponds to 4800 intervals\n",
    "\tx1 = x0 + offset\n",
    "\t\n",
    "    # But only download until xf\n",
    "\tif x1 > xf:\n",
    "\t\tx1 = xf\n",
    "\t\n",
    "\tx0_str = x0.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\tx1_str = x1.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Try download. \n",
    "    # If now data available for interval, skip.\n",
    "\ttry:\n",
    "\t\ttmp = oanda.get_history(instrument=instrument, granularity=gran,\n",
    "                                start=x0_str, end=x1_str).get(\"candles\")\n",
    "\texcept:\n",
    "\t\ttmp = {}\n",
    "\t\n",
    "    # If data available, append to data frame.\n",
    "\tif tmp != {}:\n",
    "\t\tapp = pd.DataFrame(tmp, columns=tmp.pop(0)).loc[:,('time', 'closeBid', 'closeAsk')]\n",
    "\t\tapp.columns = ('time',  sym + ' Bid', sym + ' Ask')\n",
    "\t\tapp.loc[:, 'time'] = pd.to_datetime(app['time'])\n",
    "\t\tapp = app.set_index('time')\n",
    "\t\t\n",
    "\t\tdf = pd.concat([df, app])\n",
    "\n",
    "    # Set old x1 as new x1 plus one second for next step and call self again \n",
    "    # as long as xf isn't included in download.\n",
    "\tif x1 < xf:\n",
    "\t\tx0 = x1 + pd.DateOffset(seconds=1)\n",
    "\t\tdf = oanda_download(df, x0, xf, gran, instrument)\n",
    "\t\t\n",
    "\treturn df\n",
    "\n",
    "\n",
    "# String names for file naming\n",
    "exportstring = granop+'_'+y1+'_'+y2\n",
    "importstring = exportstring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of symbols to download\n",
    "symbols = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "           \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\", \"XAU_USD\"]\n",
    "symbolseur = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_EUR\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "              \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\"]\n",
    "\n",
    "for sym in symbols:\n",
    "    x0 = dt.datetime(int(y1), 1, 1, 0, 0, 0)\n",
    "    xf = dt.datetime(int(y2),12,31,23,59,59)\n",
    "    # If last date is later than current time, use current time as end point\n",
    "    if dt.datetime.now() < xf:\n",
    "        xf = dt.datetime.now()\n",
    "\n",
    "    # Create data frame \n",
    "    df = pd.DataFrame(data = None, columns = ('time',  sym + ' Bid', sym + ' Ask'))\n",
    "    df = df.set_index('time')\n",
    "    \n",
    "    # See if a file exists with previously downloaded data.\n",
    "    # If it doesn't for y2, loop down to y1; if all fails download from scratch.\n",
    "    yloop = int(y2)\n",
    "    while yloop >= int(y1):\n",
    "        try:\n",
    "            importstring = granop+'_'+y1+'_'+str(yloop)\n",
    "            df = pd.read_csv(importstring + '_curr_' + sym + '.csv', engine='c', index_col=\"time\", parse_dates=True)\n",
    "            last_date = df.index[-1]\n",
    "            print 'Found ' + sym + ' file. xf is ' +  xf.strftime('%Y-%m-%dT%H:%M:%S') +'.'\n",
    "            break\n",
    "        except:\n",
    "            yloop = yloop-1\n",
    "            print yloop\n",
    "    try:\n",
    "        print 'Last date in file is ' +  last_date.strftime('%Y-%m-%dT%H:%M:%S') + '.'\n",
    "    except:\n",
    "        last_date = x0\n",
    "        print 'Could not find or read ' + sym + ' file.'\n",
    "\n",
    "        \n",
    "    df = oanda_download(df, last_date, xf, gran, sym)\n",
    "    df.loc[:, sym] = 0.5*(df.loc[:, sym + ' Bid'] + df.loc[:, sym + ' Ask'])\n",
    "    df.to_csv(exportstring + '_curr_' + sym + '.csv', index=True)\n",
    "    \n",
    "    if sym[0:3] != \"EUR\":\n",
    "        continue\n",
    "\n",
    "    \n",
    "\n",
    "    if sym == symbols[0]:\n",
    "        temp = df.copy()\n",
    "        # 'merged' is the dataframe in which we write all the data, so we fill it up with AUD as a starter\n",
    "        merged = temp\n",
    "        # Loop through for all the other currencies\n",
    "    else:\n",
    "        newfile = df.copy()\n",
    "        # Attach a new column to the table for the currency, but only take time values which exist for all currencies (inner join).\n",
    "        merged = pd.merge(merged, newfile, how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "        \n",
    "\n",
    "# Rename dataframe for clarity and select only midpoint columns\n",
    "rates_data = merged.loc[:, symbols]\n",
    "# Add a column with the EUR/EUR exchange rate\n",
    "rates_data.insert(3, 'EUR_EUR', 1.)\n",
    "# Sort columns alphabetically by their index\n",
    "rates_data = rates_data.reindex_axis(sorted(rates_data.columns), axis=1)\n",
    "# Export dataframe to a csv file. Index false indicates that we don't want to export the row numbers as well\n",
    "rates_data.to_csv(exportstring+'_rates.csv')\n",
    "\n",
    "\n",
    "# Export all timestamps starting with the second row because that will be the first return we calculate\n",
    "pd.Series(data=rates_data.index.values, name='time').to_csv(exportstring+'_timestamps.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
