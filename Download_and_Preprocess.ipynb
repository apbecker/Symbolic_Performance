{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import oandapy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set initial year for data y1, end year of data y2, granularity of data gran.\n",
    "y1 = '2005'\n",
    "y2 = '2018'\n",
    "gran = 'M10'\n",
    "\n",
    "# Open oanda client with access token in practice environmet\n",
    "oanda  = oandapy.API(environment=\"practice\",\n",
    "                     access_token=\"f975d225ddd7712af4e145442fb86141-5f189c470c208e9be38da4f8cb3b27db\")\n",
    "\n",
    "\n",
    "# Set Default Values for M10\n",
    "# \n",
    "# Granularity of data in pandas freq, and as integer in minutes dl_interval,\n",
    "# Granularity for output format granop, interval size as tine step diff,\n",
    "# offset between two different download attempts offset (5000 is maximum via oanda)\n",
    "freq = '10T'\n",
    "dl_interval = 10\n",
    "granop = gran\n",
    "diff = '0 days, 00:10:00'\n",
    "offset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\n",
    "## Potential customization for other intervals to write as function\n",
    "# dl_interval = gran[1:]\n",
    "\n",
    "# if gran[0] == 'M':\n",
    "# \tfreq = dl_interval + 'T'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'M0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:0' + dl_interval + ':00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'M' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:' + dl_interval + ':00'\n",
    "# \toffset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\t\n",
    "# elif gran[0] == 'H':\n",
    "# \tfreq = str(dl_interval) + 'H'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'H0' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 0' + dl_interval + ':00:00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'H' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, ' + dl_interval + ':00:00'\n",
    "# \toffset = pd.DateOffset(hours=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'S':\n",
    "# \tfreq = str(dl_interval) + 'S'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'S0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:00:0' + dl_interval\n",
    "# \telse:\n",
    "# \t\tgranop = 'S' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 00:00:' + dl_interval\n",
    "# \toffset = pd.DateOffset(seconds=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'D':\n",
    "# \tfreq = 'D'\n",
    "# \tgranop = gran\n",
    "# \tdiff = '1 day, 00:00:00'\n",
    "# \toffset = pd.DateOffset(days=4800*int(dl_interval))\n",
    "\n",
    "\n",
    "# Function to download from oanda\n",
    "def oanda_download(df, x0, xf, gran, instrument):\n",
    "    # Each call of the function downloads data between x0 and xf that hasn't been downloaded previously.\n",
    "    # To make as few requests to oanda as possible, make the interval as large as safely possible.\n",
    "    # Oanda allows 5000 data points at a time; for margin we pull data from up to 4800 time points.\n",
    "    # This is to account for potential duplicate data that'd throw an exception.\n",
    "\tif gran[0] == 'S':\n",
    "\t\toffset = pd.DateOffset(seconds=4800*int(gran[1:]))\n",
    "\telif gran[0] == 'M':\n",
    "\t\toffset = pd.DateOffset(minutes=4800*int(gran[1:]))\n",
    "\telif gran[0] == 'H':\n",
    "\t\toffset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "\telse:\n",
    "\t\toffset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "\t\n",
    "    # If the end point given by user is later than current time, shorten interval.\n",
    "\tif dt.datetime.now() < xf:\n",
    "\t\txf = dt.datetime.now()\n",
    "\t\n",
    "    # Download data between x0 and x1, which corresponds to 4800 intervals\n",
    "\tx1 = x0 + offset\n",
    "\t\n",
    "    # But only download until xf\n",
    "\tif x1 > xf:\n",
    "\t\tx1 = xf\n",
    "\t\n",
    "\tx0_str = x0.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\tx1_str = x1.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Try download. \n",
    "    # If now data available for interval, skip.\n",
    "\ttry:\n",
    "\t\ttmp = oanda.get_history(instrument=instrument, granularity=gran,\n",
    "                                start=x0_str, end=x1_str).get(\"candles\")\n",
    "\texcept:\n",
    "\t\ttmp = {}\n",
    "\t\n",
    "    # If data available, append to data frame.\n",
    "\tif tmp != {}:\n",
    "\t\tapp = pd.DataFrame(tmp, columns=tmp.pop(0)).loc[:,('time', 'closeBid', 'closeAsk')]\n",
    "\t\tapp.columns = ('time',  sym + ' Bid', sym + ' Ask')\n",
    "\t\tapp.loc[:, 'time'] = pd.to_datetime(app['time'])\n",
    "\t\tapp = app.set_index('time')\n",
    "\t\t\n",
    "\t\tdf = pd.concat([df, app])\n",
    "\n",
    "    # Set old x1 as new x1 plus one second for next step and call self again \n",
    "    # as long as xf isn't included in download.\n",
    "\tif x1 < xf:\n",
    "\t\tx0 = x1 + pd.DateOffset(seconds=1)\n",
    "\t\tdf = oanda_download(df, x0, xf, gran, instrument)\n",
    "\t\t\n",
    "\treturn df\n",
    "\n",
    "\n",
    "# String names for file naming\n",
    "exportstring = \"data/\" + granop+'_'+y1+'_'+y2\n",
    "importstring = \"data/\" + exportstring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found EUR_AUD file. xf is 2018-05-04T12:27:40.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_CAD file. xf is 2018-05-04T12:27:43.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_CHF file. xf is 2018-05-04T12:27:46.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_GBP file. xf is 2018-05-04T12:27:50.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_JPY file. xf is 2018-05-04T12:27:53.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found USD_MXN file. xf is 2018-05-04T12:27:57.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_NOK file. xf is 2018-05-04T12:28:00.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_NZD file. xf is 2018-05-04T12:28:03.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_SEK file. xf is 2018-05-04T12:28:06.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_SGD file. xf is 2018-05-04T12:28:10.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_USD file. xf is 2018-05-04T12:28:13.\n",
      "Last date in file is 2018-05-04T12:10:00.\n",
      "Found EUR_ZAR file. xf is 2018-05-04T12:28:16.\n",
      "Last date in file is 2018-05-04T12:10:00.\n"
     ]
    }
   ],
   "source": [
    "# List of symbols to download\n",
    "symbols = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "           \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\"]\n",
    "symbolseur = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_EUR\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "              \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\"]\n",
    "\n",
    "for sym in symbols:\n",
    "    x0 = dt.datetime(int(y1), 1, 1, 0, 0, 0)\n",
    "    xf = dt.datetime(int(y2),12,31,23,59,59)\n",
    "    # If last date is later than current time, use current time as end point\n",
    "    if dt.datetime.now() < xf:\n",
    "        xf = dt.datetime.now()\n",
    "\n",
    "    # Create data frame \n",
    "    df = pd.DataFrame(data = None, columns = ('time',  sym + ' Bid', sym + ' Ask'))\n",
    "    df = df.set_index('time')\n",
    "    \n",
    "    # See if a file exists with previously downloaded data.\n",
    "    # If it doesn't for y2, loop down to y1; if all fails download from scratch.\n",
    "    yloop = int(y2)\n",
    "    while yloop >= int(y1):\n",
    "        try:\n",
    "            importstring = \"data/\" + granop+'_'+y1+'_'+str(yloop)\n",
    "            df = pd.read_csv(importstring + '_curr_' + sym + '.csv', engine='c', index_col=\"time\", parse_dates=True)\n",
    "            last_date = df.index[-1]\n",
    "            print 'Found ' + sym + ' file. xf is ' +  xf.strftime('%Y-%m-%dT%H:%M:%S') +'.'\n",
    "            break\n",
    "        except:\n",
    "            yloop = yloop-1\n",
    "            print yloop\n",
    "    try:\n",
    "        print 'Last date in file is ' +  last_date.strftime('%Y-%m-%dT%H:%M:%S') + '.'\n",
    "    except:\n",
    "        last_date = x0\n",
    "        print 'Could not find or read ' + sym + ' file.'\n",
    "\n",
    "        \n",
    "    df = oanda_download(df, last_date, xf, gran, sym)\n",
    "    df.loc[:, sym] = 0.5*(df.loc[:, sym + ' Bid'] + df.loc[:, sym + ' Ask'])\n",
    "    df.to_csv(exportstring + '_curr_' + sym + '.csv', index=True)\n",
    "    \n",
    "\n",
    "    if sym == symbols[0]:\n",
    "        temp = df.copy()\n",
    "        # 'merged' is the dataframe in which we write all the data, so we fill it up with AUD as a starter\n",
    "        merged = temp\n",
    "        # Loop through for all the other currencies\n",
    "    else:\n",
    "        newfile = df.copy()\n",
    "        # Attach a new column to the table for the currency, but only take time values which exist for all currencies (inner join).\n",
    "        merged = pd.merge(merged, newfile, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Rename dataframe for clarity and select only midpoint columns\n",
    "rates_data = merged.loc[:, symbols]\n",
    "\n",
    "for c in rates_data.columns:\n",
    "    bc = c[:3]\n",
    "    qc = c[4:]\n",
    "    if bc != \"EUR\":\n",
    "        rates_data.insert(0, \"EUR_\"+qc, rates_data.loc[:, c] / rates_data.loc[:, \"EUR_\"+bc])\n",
    "\n",
    "# Add a column with the EUR/EUR exchange rate\n",
    "rates_data.insert(0, 'EUR_EUR', 1.)\n",
    "# Sort columns alphabetically by their index\n",
    "rates_data = rates_data.reindex(sorted(rates_data.columns), axis=1).filter(regex=\"EUR_\")\n",
    "# Export dataframe to a csv file. Index false indicates that we don't want to export the row numbers as well\n",
    "rates_data.to_csv(exportstring+'_rates.csv')\n",
    "\n",
    "\n",
    "# Export all timestamps starting with the second row because that will be the first return we calculate\n",
    "pd.Series(data=rates_data.index.values, name='time').to_csv(exportstring+'_timestamps.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EUR_AUD</th>\n",
       "      <th>EUR_CAD</th>\n",
       "      <th>EUR_CHF</th>\n",
       "      <th>EUR_EUR</th>\n",
       "      <th>EUR_GBP</th>\n",
       "      <th>EUR_JPY</th>\n",
       "      <th>EUR_MXN</th>\n",
       "      <th>EUR_NOK</th>\n",
       "      <th>EUR_NZD</th>\n",
       "      <th>EUR_SEK</th>\n",
       "      <th>EUR_SGD</th>\n",
       "      <th>EUR_USD</th>\n",
       "      <th>EUR_ZAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-02 21:00:00</th>\n",
       "      <td>1.73380</td>\n",
       "      <td>1.62835</td>\n",
       "      <td>1.5458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>139.18</td>\n",
       "      <td>8.226872</td>\n",
       "      <td>8.2385</td>\n",
       "      <td>1.88500</td>\n",
       "      <td>9.0200</td>\n",
       "      <td>2.21225</td>\n",
       "      <td>1.35495</td>\n",
       "      <td>7.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 22:00:00</th>\n",
       "      <td>1.73580</td>\n",
       "      <td>1.63025</td>\n",
       "      <td>1.5451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70630</td>\n",
       "      <td>139.15</td>\n",
       "      <td>8.223624</td>\n",
       "      <td>8.2340</td>\n",
       "      <td>1.88630</td>\n",
       "      <td>9.0200</td>\n",
       "      <td>2.21385</td>\n",
       "      <td>1.35585</td>\n",
       "      <td>7.6809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02 23:00:00</th>\n",
       "      <td>1.73280</td>\n",
       "      <td>1.62965</td>\n",
       "      <td>1.5452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70705</td>\n",
       "      <td>139.26</td>\n",
       "      <td>8.216957</td>\n",
       "      <td>8.2325</td>\n",
       "      <td>1.89040</td>\n",
       "      <td>9.0200</td>\n",
       "      <td>2.21535</td>\n",
       "      <td>1.35695</td>\n",
       "      <td>7.6804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-03 00:00:00</th>\n",
       "      <td>1.73355</td>\n",
       "      <td>1.63000</td>\n",
       "      <td>1.5452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70715</td>\n",
       "      <td>139.26</td>\n",
       "      <td>8.193846</td>\n",
       "      <td>8.2315</td>\n",
       "      <td>1.88905</td>\n",
       "      <td>9.0200</td>\n",
       "      <td>2.21540</td>\n",
       "      <td>1.35675</td>\n",
       "      <td>7.6792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-03 00:40:00</th>\n",
       "      <td>1.73305</td>\n",
       "      <td>1.62885</td>\n",
       "      <td>1.5457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70655</td>\n",
       "      <td>138.87</td>\n",
       "      <td>8.217409</td>\n",
       "      <td>8.2315</td>\n",
       "      <td>1.88835</td>\n",
       "      <td>9.0165</td>\n",
       "      <td>2.21060</td>\n",
       "      <td>1.35505</td>\n",
       "      <td>7.6696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     EUR_AUD  EUR_CAD  EUR_CHF  EUR_EUR  EUR_GBP  EUR_JPY  \\\n",
       "time                                                                        \n",
       "2005-01-02 21:00:00  1.73380  1.62835   1.5458      1.0  0.70550   139.18   \n",
       "2005-01-02 22:00:00  1.73580  1.63025   1.5451      1.0  0.70630   139.15   \n",
       "2005-01-02 23:00:00  1.73280  1.62965   1.5452      1.0  0.70705   139.26   \n",
       "2005-01-03 00:00:00  1.73355  1.63000   1.5452      1.0  0.70715   139.26   \n",
       "2005-01-03 00:40:00  1.73305  1.62885   1.5457      1.0  0.70655   138.87   \n",
       "\n",
       "                      EUR_MXN  EUR_NOK  EUR_NZD  EUR_SEK  EUR_SGD  EUR_USD  \\\n",
       "time                                                                         \n",
       "2005-01-02 21:00:00  8.226872   8.2385  1.88500   9.0200  2.21225  1.35495   \n",
       "2005-01-02 22:00:00  8.223624   8.2340  1.88630   9.0200  2.21385  1.35585   \n",
       "2005-01-02 23:00:00  8.216957   8.2325  1.89040   9.0200  2.21535  1.35695   \n",
       "2005-01-03 00:00:00  8.193846   8.2315  1.88905   9.0200  2.21540  1.35675   \n",
       "2005-01-03 00:40:00  8.217409   8.2315  1.88835   9.0165  2.21060  1.35505   \n",
       "\n",
       "                     EUR_ZAR  \n",
       "time                          \n",
       "2005-01-02 21:00:00   7.6758  \n",
       "2005-01-02 22:00:00   7.6809  \n",
       "2005-01-02 23:00:00   7.6804  \n",
       "2005-01-03 00:00:00   7.6792  \n",
       "2005-01-03 00:40:00   7.6696  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
